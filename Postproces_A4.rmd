---
title: "Postproces_A4"
author: "Oriol Calvo"
date: "30/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(stringr)
library(dplyr)
library(lubridate)
library(gridExtra)
library(corrplot)
# Text minning
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
#Treemap
library(treemap)
```


# 1 Tractament de les dades

```{r}
# Càrrega dades corpus
corpus <- read.csv("pax_corpus_355_agreements_21-04-20.csv",header = T,stringsAsFactors = T)
# Càrrega dades data
data <- read.csv("pax_data_355_agreements_21-04-20.csv",header = T,stringsAsFactors = T)
```

S'uneixen els dos dataframes fent un merge per les columnes que identifiquen el agreement Id per a cada dataset:
```{r}
data.merge <- merge(x = corpus, y = data, by.x="ï..AgreementId",by.y="AgtId")
#write.csv(data.merge,"Data.csv",row.names = FALSE)
```

## 1.1 Gràfic densitat

```{r}
df <- corpus
# Es guarden les dades en format Date
df$data <- as.Date(df$Signed.Date)
# S'agrupen les dades en funció de la data i la regió a la que pertanyen
res <- aggregate(df$Peace.Process, by=list(data=df$data, regio = df$Region), FUN=unique)
# Es desestima el dia i el mes, i ens quedem únicament amb l'any
res$year <- format(res$data, "%Y")
res$num_agr <- unlist(lapply(res$x, length), use.names=FALSE)
# Generem un dataframe altenatiu que conté únicament la info de any, regió i nombre d'acords signats
selected_columns <- c('year','regio','num_agr')
res_2 <- select(res, selected_columns)
# Es sumen els acords
densitat <- aggregate(res_2$num_agr, by=list(year=res_2$year, regio = res_2$regio), FUN=sum)

#write.csv(taula,"densitat.csv",row.names = FALSE)
rm(df,res,selected_columns,res_2)
```

```{r}
library(reshape2)
y <- dcast(taula, regio ~ year, value.var = "x")
y[is.na(y)]<-0
write.csv(y,"densitat1.csv",row.names = FALSE)
```

## 1.2 gràfic Treemap

```{r}
columna <- c("Loc1ISO","Region")
res <- count(data.merge,Loc1ISO, Region)
res$Loc1ISO[res$Loc1ISO == ""] <- NA
res <- na.omit(res)
aux <- data.frame("Country"=res$Loc1ISO,"Region"=res$Region,"freq"=res$n)
write.csv(aux,"tree.csv",row.names = FALSE)

rm(columna,aux)
```

## 1.3 gràfic Heatmap
```{r}
#aux1 <- data.merge[,c("Region","GRe")]
aux1 <- count(data.merge,Region,GRe)
aux <- data.frame("Region"=aux1$Region,"GRe"=aux1$GRe,"freq"=aux1$n)
write.csv(aux,"heatmap.csv",row.names = FALSE)
rm(aux1, aux)
```

## 1.4 gràfic Wordclouds
```{r}
text <- corpus$Agreement.Text[corpus$Region=="Americas"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_americas.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
text <- corpus$Agreement.Text[corpus$Region=="Asia and Pacific"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_asiapacific.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
text <- corpus$Agreement.Text[corpus$Region=="Europe and Eurasia"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_europe.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
text <- corpus$Agreement.Text[corpus$Region=="Middle East and North Africa"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_meast.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
text <- corpus$Agreement.Text[corpus$Region=="Cross-regional"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_cros.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
text <- corpus$Agreement.Text[corpus$Region=="Africa (excl MENA)"]
# Neteja dels texts
text <- tolower(text)
text <- tm::removeNumbers(text)
text <- str_replace_all(text, "â", "")
text <- str_replace_all(text, "  ", "")
text <- str_replace_all(text, pattern = "[[:punct:]]", " ")
text <- tm::removeWords(x = text, stopwords(kind = "SMART"))
# Es converteix en corpus
corpus_1 <- Corpus(VectorSource(text))
tdm <- TermDocumentMatrix(corpus_1) 
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
maxim <- max(v)
v <- round(v*80/maxim)
d <- data.frame(word = names(v),freq=v)
write.csv(d,"wc_africa.csv",row.names = FALSE)
rm(text,corpus_1,tdm,m,v)
```

```{r}
d1 <- read.csv("wc_cros.csv",header = T)
d1$region <- "Cross-regional"
d1 <- d1[1:100,]
d2 <- read.csv("wc_africa.csv",header = T)
d2$region <- "Africa (excl MENA)"
d2 <- d2[1:100,]
d3 <- read.csv("wc_americas.csv",header = T)
d3$region <- "Americas"
d3 <- d3[1:100,]
d4 <- read.csv("wc_asiapacific.csv",header = T)
d4$region <- "Asia and Pacific"
d4 <- d4[1:100,]
d5 <- read.csv("wc_europe.csv",header = T)
d5$region <- "Europe and Eurasia"
d5 <- d5[1:100,]
d6 <- read.csv("wc_meast.csv",header = T)
d6$region <- "Middle East and North Africa"
d6 <- d6[1:100,]
```

```{r}
latd<-rbind(d1,d2,d3,d4,d5,d6)
write.csv(latd,"wc.csv",row.names = FALSE)
```


